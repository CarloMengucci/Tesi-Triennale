{
 "metadata": {
  "name": "",
  "signature": "sha256:d39912323e9a67c686cd842e16b92490779eff26f0585070c1bc4a5e1daec914"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#rende omogenei i comportamenti con .3\n",
      "from __future__ import print_function,unicode_literals,division "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#sezione d'importazione\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import pylab as plt\n",
      "import scipy.stats as st\n",
      "import sklearn\n",
      "from statsmodels.api import RLM,OLS\n",
      "import scipy\n",
      "import pymc\n",
      "import seaborn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#scrittura funzione di regressione\n",
      "def fit (x,y):\n",
      "    slope, intercept, r_value, p_value, std_err = st.linregress(x,y)\n",
      "    return slope,intercept"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Scrittura funzione coefficiente correlazione lineare\n",
      "def r_value(x,y,slope,intercept):\n",
      "    y_est=slope*x+intercept\n",
      "    corr_y=np.corrcoef(y,y_est)\n",
      "    return corr_y[0,1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Funzione per analisi dei residui\n",
      "def residui (x,y,slope,intercept):\n",
      "    y_est=slope*x+intercept\n",
      "    return (y-y_est)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#funzione generale per il learning\n",
      "from sklearn.cross_validation import train_test_split\n",
      "def data_learning(x,y):\n",
      "    correlators=[]\n",
      "    residuals=[]\n",
      "    for i in range (100):\n",
      "        datared_train,datared_test,age_train,age_test=train_test_split(x, \n",
      "                                                                       y,\n",
      "                                                                       test_size=0.3)\n",
      "        sl_tr,intc_tr=fit(datared_train,age_train)\n",
      "        \n",
      "        correlatori=r_value(datared_test,age_test,sl_tr,intc_tr)\n",
      "        correlators.append(correlatori)\n",
      "        residui_test=residui(datared_test,age_test,sl_tr,intc_tr)\n",
      "        residuals.extend(residui_test)\n",
      "    \n",
      "    mean=np.mean(correlators)\n",
      "    std_dev=np.std(correlators)\n",
      "  \n",
      "    s,i=fit(x,y)\n",
      "    \n",
      "    f=plt.figure(figsize(20,5))\n",
      "    f,(ax1,ax2,ax3)=plt.subplots(1,3, sharey=False)\n",
      "    ax1.hist(correlators)\n",
      "    ax1.set_title('Correlators')\n",
      "    ax2.scatter(x,y)\n",
      "    ax2.plot(x,i+s*x,color='red')\n",
      "    ax2.set_title('Linear Fitting')\n",
      "    ax2.set_ylabel('Age')\n",
      "    ax3.hist(residuals)  \n",
      "    ax3.set_title('Residuals')\n",
      "    \n",
      "    return(mean,std_dev)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Metodo generale per la regressione lineare multipla\n",
      "\n",
      "from scipy.optimize import curve_fit\n",
      "\n",
      "def multifit(x1,x2,y):\n",
      "    regressore1=[]\n",
      "    regressore2=[]\n",
      "    for i in x1:\n",
      "        regressore1.append(i)\n",
      "    for a in x2:\n",
      "        regressore2.append(a)\n",
      "    \n",
      "    \n",
      "    xdata=np.array([regressore1,regressore2])\n",
      "\n",
      "    ydata=y\n",
      "\n",
      "    def f(x,p1,p2,p3):\n",
      "        return x[0]*p1+x[1]*p2+p3\n",
      "\n",
      "    popt,pcov=curve_fit(f,xdata,ydata,p0=(0,0,0))\n",
      "    return popt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Metodo per il learning multivariato\n",
      "\n",
      "\n",
      "def multifit_learn(x1,x2,y):\n",
      "    regressore1=[]\n",
      "    regressore2=[]\n",
      "    for i in x1:\n",
      "        regressore1.append(i)\n",
      "    for a in x2:\n",
      "        regressore2.append(a)\n",
      "    \n",
      "    \n",
      "    xdata=np.array([regressore1,regressore2])\n",
      "\n",
      "    ydata=y\n",
      "\n",
      "    def f(x,p1,p2,p3):\n",
      "        return x[0]*p1+x[1]*p2+p3\n",
      "\n",
      "    popt,pcov=curve_fit(f,xdata,ydata,p0=(0.0,0.0,0.0))\n",
      "    \n",
      "    \n",
      "    \n",
      "    p_1=popt[0]\n",
      "    p_2=popt[1]\n",
      "    p_3=popt[2]\n",
      "    \n",
      "    #metodo per la definizione di r \n",
      "    def r_mulvalue(x,y,p_1,p_2,p_3):\n",
      "        y_est=f(xdata,p_1,p_2,p_3)\n",
      "        y_corr=np.corrcoef(ydata,y_est)\n",
      "        r=y_corr[0][1]\n",
      "        \n",
      "        return r\n",
      "    \n",
      "    print(r_mulvalue(xdata,y,p_1,p_2,p_3)) \n",
      "    \n",
      "    #Sezione di validation splitting/elaborazione\n",
      "    correlators=[]\n",
      "    residuals=[]\n",
      "    for i in range (100):\n",
      "        reg1_train,reg1_test,reg2_train,reg2_test,age_train,age_test=train_test_split(xdata[0],\n",
      "                                                                                      xdata[1],\n",
      "                                                                                      y,\n",
      "                                                                                      test_size=0.3)\n",
      "        p_01tr,p_02tr,p_03tr=multifit(reg1_train,reg2_train,age_train)\n",
      "        \n",
      "        regdata_test=([reg1_test,reg2_test])\n",
      "            \n",
      "        correlatori=r_mulvalue(regdata_test,age_test,p_01tr,p_02tr,p_03tr)\n",
      "        correlators.append(correlatori)\n",
      "        \n",
      "        \n",
      "       \n",
      "        \n",
      "        residualspopt=age_test-f(regdata_test,p_01tr,p_02tr,p_03tr)\n",
      "        residuals.extend(residualspopt)\n",
      "        \n",
      "        \n",
      "\n",
      "    mean=np.mean(correlators)\n",
      "    std_dev=np.std(correlators)  \n",
      "   \n",
      "    #Sezione grafica\n",
      "    y_est=f(xdata,p_1,p_2,p_3)\n",
      "    fig=plt.figure(figsize(20,5))\n",
      "    f,(ax1,ax2,ax3)=plt.subplots(1,3,sharey=False)\n",
      "    ax1.hist(correlators)\n",
      "    ax1.set_title('Correlators')\n",
      "    ax2.hist(residuals)\n",
      "    ax2.set_title('Residuals')\n",
      "    ax3.scatter(y,y_est)\n",
      "    ax3.plot(y,y,color='Red')\n",
      "    ax3.set_xlabel('Data')\n",
      "    ax3.set_ylabel('Previsions')\n",
      "    return mean,std_dev"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Metodo per multilearning con interazioni x1*x2\n",
      "from scipy.optimize import curve_fit\n",
      "\n",
      "def multifit_p(x1,x2,y):\n",
      "    regressore1=[]\n",
      "    regressore2=[]\n",
      "    for i in x1:\n",
      "        regressore1.append(i)\n",
      "    for a in x2:\n",
      "        regressore2.append(a)\n",
      "    \n",
      "    \n",
      "    xdata=np.array([regressore1,regressore2])\n",
      "\n",
      "    ydata=y\n",
      "\n",
      "    def f(x,p1,p2,p3,p4):\n",
      "        return x[0]*p1+x[1]*p2+x[0]*x[1]*p3+p4\n",
      "\n",
      "    popt,pcov=curve_fit(f,xdata,ydata,p0=(0,0,0,0))\n",
      "    return popt\n",
      "\n",
      "def multifit_learn_prod(x1,x2,y):\n",
      "    regressore1=[]\n",
      "    regressore2=[]\n",
      "    for i in x1:\n",
      "        regressore1.append(i)\n",
      "    for a in x2:\n",
      "        regressore2.append(a)\n",
      "    \n",
      "    \n",
      "    xdata=np.array([regressore1,regressore2])\n",
      "\n",
      "    ydata=y\n",
      "\n",
      "    def f(x,p1,p2,p3,p4):\n",
      "        return x[0]*p1+x[1]*p2+x[0]*x[1]*p3+p4\n",
      "\n",
      "    popt,pcov=curve_fit(f,xdata,ydata,p0=(0.0,0.0,0.0,0.0))\n",
      "    \n",
      "    \n",
      "    \n",
      "    p_1=popt[0]\n",
      "    p_2=popt[1]\n",
      "    p_3=popt[2]\n",
      "    p_4=popt[3]\n",
      "   \n",
      "    #metodo per la definizione di r \n",
      "    def r_mulvalue(x,y,p_1,p_2,p_3,p_4):\n",
      "        y_est=f(xdata,p_1,p_2,p_3,p_4)\n",
      "        y_corr=np.corrcoef(ydata,y_est)\n",
      "        r=y_corr[0][1]\n",
      "        \n",
      "        return r\n",
      "    \n",
      "    print(r_mulvalue(xdata,y,p_1,p_2,p_3,p_4)) \n",
      "    \n",
      "    #Sezione di validation splitting/elaborazione\n",
      "    correlators=[]\n",
      "    residuals=[]\n",
      "    for i in range (100):\n",
      "        reg1_train,reg1_test,reg2_train,reg2_test,age_train,age_test=train_test_split(xdata[0],\n",
      "                                                                                      xdata[1],\n",
      "                                                                                      y,\n",
      "                                                                                      test_size=0.3)\n",
      "        p_01trp,p_02trp,p_03trp,p_04trp=multifit_p(reg1_train,reg2_train,age_train)\n",
      "        \n",
      "        regdata_test=([reg1_test,reg2_test])\n",
      "            \n",
      "        correlatori=r_mulvalue(regdata_test,age_test,p_01trp,p_02trp,p_03trp,p_04trp)\n",
      "        correlators.append(correlatori)\n",
      "        \n",
      "        \n",
      "       \n",
      "        \n",
      "        residualspopt=age_test-f(regdata_test,p_01trp,p_02trp,p_03trp,p_04trp)\n",
      "        residuals.extend(residualspopt)\n",
      "        \n",
      "        \n",
      "\n",
      "    mean=np.mean(correlators)\n",
      "    std_dev=np.std(correlators)  \n",
      "   \n",
      "    #Sezione grafica\n",
      "    y_est=f(xdata,p_1,p_2,p_3,p_4)\n",
      "    fig=plt.figure(figsize(20,5))\n",
      "    f,(ax1,ax2,ax3)=plt.subplots(1,3,sharey=False)\n",
      "    ax1.hist(correlators)\n",
      "    ax1.set_title('Correlators')\n",
      "    ax2.hist(residuals)\n",
      "    ax2.set_title('Residuals')\n",
      "    ax3.scatter(y,y_est)\n",
      "    ax3.plot(y,y,color='Red')\n",
      "    ax3.set_xlabel('Data')\n",
      "    ax3.set_ylabel('Previsions')\n",
      "    return mean,std_dev"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Funzione che ritorna arrays contenenti indici per lo splitting in train e test (randomizzata)\n",
      "def rand_tt_ar_split_idx(size,percent,train_percent,start_point=0):        \n",
      "      \n",
      "        tot_index=np.arange(size)\n",
      "        slice_size=size*percent//100\n",
      "        slice_index=np.arange(start_point,slice_size)\n",
      "        train_idx_size=train_percent/100\n",
      "        \n",
      "        \n",
      "        train_index,test_index=train_test_split(slice_index,train_size=train_idx_size)\n",
      "            \n",
      "        test_index_l=[]\n",
      "            \n",
      "        for i in test_index:\n",
      "                test_index_l.append(i)\n",
      "            \n",
      "          \n",
      "            \n",
      "        for i in tot_index: \n",
      "            if i not in train_index:\n",
      "                if i not in test_index_l:        \n",
      "                    test_index_l.append(i)\n",
      "            \n",
      "        test_index_tot=np.array(test_index_l)\n",
      "        test_index_l=[]\n",
      "            \n",
      "        return (train_index,test_index_tot)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Funzione di Learning avanzato per troncamento dati\n",
      "def tt_adv_split_learning(x,y,slice_percent,train_percent,n_steps):\n",
      "    \n",
      "    x_ar=np.array(x)\n",
      "    y_ar=np.array(y)\n",
      "    inc=len(x_ar)//n_steps\n",
      "    \n",
      "    it_count=0\n",
      "    sp=slice_percent\n",
      "    tp=train_percent\n",
      "    correlators=[]\n",
      "    residuals=[]\n",
      "    \n",
      "    for i in range (n_steps):\n",
      "        \n",
      "        print (it_count)\n",
      "          \n",
      "        \n",
      "        for i in range (10):\n",
      "\n",
      "            tr_index,ts_index=rand_tt_ar_split_idx(len(x_ar),sp,tp,it_count)\n",
      "\n",
      "            xdata_train=x[tr_index]\n",
      "            xdata_test=x[ts_index]\n",
      "\n",
      "            ydata_train=y[tr_index]\n",
      "            ydata_test=y[ts_index]\n",
      "            \n",
      "            if len(xdata_train)|len(ydata_train)==0:\n",
      "                break\n",
      "            \n",
      "            sl_tr,intc_tr=fit(xdata_train,ydata_train)\n",
      "        \n",
      "            correlatori=r_value(xdata_test,ydata_test,sl_tr,intc_tr)\n",
      "            correlators.append(correlatori)\n",
      "            residui_test=residui(xdata_test,ydata_test,sl_tr,intc_tr)\n",
      "            residuals.extend(residui_test)\n",
      "        \n",
      "        c=it_count+inc\n",
      "        it_count=c\n",
      "    \n",
      "    mean=np.mean(correlators)\n",
      "    std_dev=np.std(correlators)\n",
      "    s,i=fit(x,y)\n",
      "    residui_g=residui(x,y,s,i)\n",
      "    \n",
      "    f=plt.figure(figsize(20,5))\n",
      "    f,(ax1,ax2,ax3)=plt.subplots(1,3, sharey=False)\n",
      "    ax1.hist(correlators)\n",
      "    ax1.set_title('Correlators')\n",
      "    ax2.scatter(x,y)\n",
      "    ax2.plot(x,i+s*x,color='red')\n",
      "    ax2.set_title('Linear Fitting')\n",
      "    ax3.hist(residuals)  \n",
      "    ax3.set_title('Residuals')\n",
      "    \n",
      "    \n",
      "    sxr,ixr=fit(x,residui_g)\n",
      "    syr,iyr=fit(y,residui_g)\n",
      "    \n",
      "    f1=plt.figure(figsize(20,5))\n",
      "    f1,(ax_1,ax_2)=plt.subplots(1,2, sharey=False)\n",
      "    ax_1.scatter(x,residui_g)\n",
      "    seaborn.regplot(x,residui_g,ci=95,color='red',ax=ax_1)\n",
      "    ax_2.scatter(residui_g[:-1],residui_g[1:])\n",
      "    seaborn.regplot(residui_g[:-1],residui_g[1:],ci=95,color='red',ax=ax_2)\n",
      "    ax_1.set_title('X vs Residuals')\n",
      "    ax_2.set_title('Residuals vs Residuals')\n",
      "    ax_1.hlines(0,min(x),max(x),color='black')\n",
      "    ax_2.hlines(0,min(y),max(y),color='black')\n",
      "    \n",
      "    s_p,i_p=fit(y,i+s*x)\n",
      "    plt.figure(figsize(8,5))\n",
      "    plt.scatter(y,i+s*x)\n",
      "    seaborn.regplot(y,y,ci=95,color='red', label='Ideal tendency')\n",
      "    seaborn.regplot(y,i_p+s_p*y,ci=95,color='orange',label='Estimated tendency')\n",
      "    plt.title('Previsions')\n",
      "    plt.legend(loc='upper left')\n",
      "    return (mean,std_dev) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x=randn(500)\n",
      "\n",
      "noise=randn(500)\n",
      "\n",
      "y=x*2+noise\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tt_adv_split_learning(x,y,100,70,3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#blocchi di testing per la valutazione del bias con dati generati (slicing del database iniziale)\n",
      "\n",
      "y_index = (y<2)&(y>-2)\n",
      "y_slice = y[y_index]\n",
      "          \n",
      "x_slice=x[y_index]\n",
      "\n",
      "s,i=fit(x,y)\n",
      "s_s,i_s=fit(x_slice,y_slice)\n",
      "\n",
      "plt.figure(figsize=(8,5))\n",
      "plt.scatter(x,y,color='blue')\n",
      "plt.scatter(x_slice,y_slice,color='green')\n",
      "plt.plot(x,i+s*x,color='red', label='Total dataset Tendency')\n",
      "seaborn.regplot(x_slice,y_slice,ci=95,color='orange', label='Sliced dataset Tendency')\n",
      "plt.legend(loc='upper left')\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tt_adv_split_learning(x_slice,y_slice,100,70,3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}